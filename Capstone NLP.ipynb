{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import bokeh \n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression=pd.read_csv(\"/Users/yonilevine/Desktop/Capstone/datasets/depressionnlp.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depression['text'] = depression[\"text\"].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt = CountVectorizer()\n",
    "X = cvt.fit_transform(depression[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpus: 42773\n",
      "Number of words that occur more than fifty times: 3569\n",
      "\n",
      "Least common: \n",
      " \n",
      "flu            51\n",
      "household      51\n",
      "wherever       51\n",
      "texas          51\n",
      "television     51\n",
      "technically    51\n",
      "argued         51\n",
      "associate      51\n",
      "someones       51\n",
      "cleaned        51\n",
      "begins         51\n",
      "sharp          51\n",
      "blessed        51\n",
      "scale          51\n",
      "catching       51\n",
      "receiving      51\n",
      "rape           51\n",
      "chores         51\n",
      "christ         51\n",
      "rope           51\n",
      "dtype: int64 \n",
      "\n",
      "Most common: \n",
      " \n",
      "to      165010\n",
      "and     149728\n",
      "the     108010\n",
      "my       96925\n",
      "it       72602\n",
      "me       69100\n",
      "of       68654\n",
      "that     62042\n",
      "in       52560\n",
      "but      47614\n",
      "have     47349\n",
      "is       43860\n",
      "for      42947\n",
      "was      39667\n",
      "just     38731\n",
      "so       37967\n",
      "this     36669\n",
      "with     35865\n",
      "like     30498\n",
      "not      29126\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_df = pd.DataFrame(cvt.transform(depression['text']).todense(),\n",
    "                       columns=cvt.get_feature_names())\n",
    "\n",
    "word_counts = X_df.sum(axis=0)\n",
    "print 'Number of words in corpus: ' + str(len(word_counts))\n",
    "word_counts = word_counts[word_counts > 50]\n",
    "print 'Number of words that occur more than fifty times: ' + str(len(word_counts)) + '\\n'\n",
    "print 'Least common: \\n \\n', word_counts.sort_values(ascending = False).tail(20), '\\n'\n",
    "print 'Most common: \\n \\n', word_counts.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvt = CountVectorizer(ngram_range=(2,6))\n",
    "X_all = cvt.fit_transform(depression[\"text\"])\n",
    "X_all_sum = np.sum(X_all, axis=0)\n",
    "word_counts = [(word, X_all_sum[0, index])\n",
    "              for index, word in enumerate(cvt.get_feature_names())]\n",
    "word_counts.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depression_train, depression_test = train_test_split(depression, \n",
    "                                               stratify=depression.insuicide,\n",
    "                                               test_size=.3, \n",
    "                                               random_state=9245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('cls', MultinomialNB())]) \n",
    "pipeline.fit(depression_train['text'], depression_train['insuicide'])\n",
    "\n",
    "\n",
    "pipeline.score(depression_test['text'], depression_test['insuicide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('cls', BernoulliNB())]) \n",
    "pipeline.fit(depression_train['text'], depression_train['insuicide'])\n",
    "\n",
    "pipeline.score(depression_test['text'], depression_test['insuicide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('cls', LogisticRegression())]) \n",
    "pipeline.fit(depression_train['text'], depression_train['insuicide'])\n",
    "\n",
    "pipeline.score(depression_test['text'], depression_test['insuicide'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('cls', RandomForestClassifier(n_estimators=200, random_state=9245))])\n",
    "    \n",
    "pipeline.fit(depression_train['text'], depression_train['insuicide'])\n",
    "\n",
    "\n",
    "pipeline.score(depression_test['text'], depression_test['insuicide'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression.insuicide.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8537/17397.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={'penalty':['l1','l2'], 'C':[.01,.05,.1,.5,1.0,5,10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lrgrid=GridSearchCV(LogisticRegression(),param_grid=params,verbose=1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('gridsearch',lrgrid),\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "    ]) \n",
    "pipeline.fit(depression_train['text'], depression_train['insuicide'])\n",
    "\n",
    "pipeline.score(depression_test['text'], depression_test['insuicide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
